<h3 style="font-size: 2em;"> El-Emperador_Model Recipe </h3>


•This repo contains the model recipe for finetuning the model from scratch. 

•The Jupyter notebook contains the necessary libraries and steps to create a model using the ORPO Trainer. 

Note:total training time took ~1 hour for 5 epochs.

Reference Articles: 
1) https://www.databricks.com/blog/efficient-fine-tuning-lora-guide-llms

2) https://mlabonne.github.io/blog/posts/2024-04-19_Fine_tune_Llama_3_with_ORPO.html

Training Charts

Evaluation Charts:
![image](https://github.com/user-attachments/assets/0164a15c-767a-4f17-955d-10e11642623d)
![image](https://github.com/user-attachments/assets/9924fd80-8baf-4a69-ad65-e257db707bab)
![image](https://github.com/user-attachments/assets/209fda8f-0ca3-4c67-9a83-56d6a152e727)
![image](https://github.com/user-attachments/assets/f1ce23a0-2a8d-474b-988d-3e06d05352c1)
![image](https://github.com/user-attachments/assets/c600bdc4-e037-48e6-a59d-f77811941eef)
![image](https://github.com/user-attachments/assets/0321df84-427e-40e8-ba46-11edfebfa2a7)
![image](https://github.com/user-attachments/assets/218f22f0-784e-46f5-bb6b-f249325a045f)
![image](https://github.com/user-attachments/assets/c5964572-a9b4-4eaf-bb89-1e8e440b4a6a)







